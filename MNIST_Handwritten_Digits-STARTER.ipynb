{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](http://yann.lecun.com/exdb/mnist/) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "95.3% [Lecun et al., 1998](http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf)\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "from ipywidgets import FloatProgress\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:178.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Define transforms\n",
    "## YOUR CODE HERE ##\n",
    "##Define the transformation: Convert to tensor & normalize \n",
    "transform_act = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "## YOUR CODE HERE ##\n",
    "#Load the training dataset\n",
    "train_data = torchvision.datasets.MNIST(root='./data',\n",
    "                                        transform =transform_act,\n",
    "                                        train = True, \n",
    "                                        download = True)\n",
    "\n",
    "#train_data.data = train_data.data.view(train_data.data.size(0), -1)\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
    "                                          batch_size=8,\n",
    "                                          shuffle=True)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "## YOUR CODE HERE ##\n",
    "#Load the testing dataset\n",
    "test_data = torchvision.datasets.MNIST(root=\"./data/\",\n",
    "                                       transform = transform_act,\n",
    "                                       train = False,\n",
    "                                       download = True)\n",
    "#test_data.data = test_data.data.view(test_data.data.size(0), -1)\n",
    "\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_data,\n",
    "                                               batch_size = 8,\n",
    "                                               shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader size: 60000\n",
      "Train DataLoader size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data_size = len(train_data_loader.dataset)\n",
    "print(\"Train DataLoader size:\", train_data_size)\n",
    "test_data_size = len(test_data_loader.dataset)\n",
    "print(\"Train DataLoader size:\", test_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 28, 28])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 1, 28, 28])\n",
      "torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "#Check the size and the shape of the training dataset \n",
    "dataiter = iter(train_data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "#Check the size and the shape of the testing dataset \n",
    "dataiter = iter(test_data_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 60,000 training data and 10,000 testing data. Each batch consists of 8 images, each image's size is 28X28 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose the totensor and normalization, since  we need to convert the image into number, so we use the totensor to indicate a single grayscale channel. For the normalization, we normalize the data to help improve model convergence and performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "    \n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOMklEQVR4nO3de4xc9XnG8eexWWyusR2C5YJTDLUDJgom2ZpUXERAoQSlMlEbCpEik1Itf8QVaWlaFBSBqkpFaQNtU0B1ghOTpnaJCMIqNMS4qChpY3khji+YW7kIjC+lbjA2ifHl7R97HG1g5zfrOXOz3+9HGs3MeefMeTX2s2fm/ObMzxEhAEe+Cb1uAEB3EHYgCcIOJEHYgSQIO5DEUd3c2NGeFJN1XDc3CaTyC+3W27HHY9Vqhd325ZL+TtJESd+IiNtKj5+s43SeL62zSQAFq2NVw1rLb+NtT5R0p6RPSJor6Rrbc1t9PgCdVecz+3xJz0fECxHxtqTlkha0py0A7VYn7KdIemXU/VerZb/C9pDtYdvDe7WnxuYA1NHxo/ERsTgiBiNicECTOr05AA3UCftmSTNH3T+1WgagD9UJ+xpJs23Psn20pKslrWhPWwDareWht4jYZ3uRpEc0MvS2JCI2tq0zAG1Va5w9Ih6W9HCbegHQQXxdFkiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5BErSmbbb8k6U1J+yXti4jBdjQFoP1qhb3ysYh4vQ3PA6CDeBsPJFE37CHpB7afsD001gNsD9ketj28V3tqbg5Aq+q+jb8gIjbbPlnSSttPR8Tjox8QEYslLZakEz0tam4PQItq7dkjYnN1vV3SA5Lmt6MpAO3XcthtH2f7hIO3JV0maUO7GgPQXnXexk+X9IDtg8/zzxHx/bZ0BaDtWg57RLwg6Zw29gKggxh6A5Ig7EAShB1IgrADSRB2IIl2nAiDw9jEsz9QrL/46ffWev7J2xvXTr7rP2s9Nw4Ne3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9iPAhHlzG9aevuGY4rqPXPL3xfqsoya31NNBb8XbDWvPf3Ficd01P59VrH/t2wuK9ZmPvtmwFmvWF9c9ErFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHNG9SVpO9LQ4z5d2bXuHC3/k7GL9mUXlse4HP3Znw9pZAwMt9XQkeHZv4zH+T676o+K6c64bbnc7XbE6Vmln7PBYNfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE57N3wetDv1Wsf/HG5cX67x7/epMtHJlj6UOvXFys//bUDcV66XX7l0vuLq77Zf1msX44arpnt73E9nbbG0Ytm2Z7pe3nquupnW0TQF3jeRv/LUmXv2PZTZJWRcRsSauq+wD6WNOwR8Tjkna8Y/ECSUur20slXdnetgC0W6uf2adHxJbq9lZJ0xs90PaQpCFJmqxjW9wcgLpqH42PkTNpGp5NExGLI2IwIgYHNKnu5gC0qNWwb7M9Q5Kq68JcnQD6QathXyFpYXV7oaQH29MOgE5p+pnd9jJJF0s6yfarkm6RdJuk+2xfJ+llSVd1ssl+1+x89Ptu/uti/f1HlX/bvZkFz/5Ow9ru208trnvMa7uL9WeGysdZ/unj/1isz5/U+u8lXHPSj4v10wZ+1uQZ6v3m/ZGmadgj4poGJX6FAjiM8HVZIAnCDiRB2IEkCDuQBGEHkuAU13HyuY2H1/5g2b8W1202tLZid/mkwT976DPF+pyb1zWsTX7rteK6zQbG5lxfrv/lh8q9/ezsKQ1rkz63tbjuTaf/W7FeZzrpuQP7i/Vn75pfrJ+5eFexfmDtU4fcU6exZweSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJJiyeZxeXHZOw9rGi5YU133orfcU63dd+3vFun+0tlg/Uk0456xi/enrTyjW/+GyexvWLjumfGpvMw/snlas33FLo5NFR5y4rHz6bquYshkAYQeyIOxAEoQdSIKwA0kQdiAJwg4kwTh7ZcIHzyzWl3//mw1rx/ro4rpXfOYPy9v+j58U62jNhHlzG9Z2zi6P0Z/xJ5uK9Xve/1hLPR30yVM+Umv9RhhnB0DYgSwIO5AEYQeSIOxAEoQdSIKwA0nwu/GVhfc/UqyXxtIv/OnvF9ed8uPyb4h375sOuZR+u/34teV1t25u/PsFkqTv1htn74Wme3bbS2xvt71h1LJbbW+2vba6XNHZNgHUNZ638d+SdPkYy++IiHnV5eH2tgWg3ZqGPSIel7SjC70A6KA6B+gW2V5Xvc1vOFmZ7SHbw7aH92pPjc0BqKPVsN8t6QxJ8yRtkfTVRg+MiMURMRgRgwOa1OLmANTVUtgjYltE7I+IA5K+Lqk85SWAnmsp7LZnjLr7KUkbGj0WQH9oOs5ue5mkiyWdZPtVSbdIutj2PI0MEb8kqcks3v3v08f/b7F+oFDb9tqU4rrv2fP8oTeE2iZMbjx/++7LP1Rc94avLC/WDxT/R0hnPbCoWJ+t1cV6JzQNe0SM9Wv393SgFwAdxNdlgSQIO5AEYQeSIOxAEoQdSIJTXCsTXf67dyD2d6kTHDRx7pxifdecKcX6tD9+uWFtxW/cXVx3b5N/7zMfLA+tzVnU/aG1ZtizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLNX9kf5lMWSY6b8olj3UeWXOfbta3nbndZsrNs7dxfrb3z01Ia1tz9X/mnDWz6woli/7Jjytkvu23Vysf63t11VrM/55n+1vO1eYc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0k4onsTBp/oaXGeL+3a9g7Fi8vKU/RuvGhJy899/tqri/Wdw+8r1md9t3NT7b1x9pRi/fa/urNYf3TX2cX60NQnGtb+/a3GY/CStL/JvmjTz3+tWH/oGxc2rE3/0RvFdeMnG4v1frU6Vmln7PBYNfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zj9OLyxlP8rr+wPKnthMP4b+r/HSifq/8XWy8p1td87cMNa1PuPfzOCe93tcbZbc+0/Zjtp2xvtH1DtXya7ZW2n6uup7a7cQDtM55dzj5JN0bEXEkflfR523Ml3SRpVUTMlrSqug+gTzUNe0RsiYgnq9tvStok6RRJCyQtrR62VNKVHeoRQBsc0m/Q2T5N0rmSVkuaHhFbqtJWSdMbrDMkaUiSJuvYlhsFUM+4jxzZPl7S/ZK+EBE7R9di5CjfmEf6ImJxRAxGxOCAJtVqFkDrxhV22wMaCfp3IuJ71eJttmdU9RmStnemRQDt0PRtvG1LukfSpoi4fVRphaSFkm6rrh/sSId9YtbV6xrWBv/0huK6BwbKz/3la5cV66cf3bm/o/e+fkGxXho6k5oPn00Rw2v9Yjyf2c+X9FlJ622vrZZ9SSMhv8/2dZJellT+oW0APdU07BHxQ0ljDtJLOjy/IQMkdPh+tQvAISHsQBKEHUiCsANJEHYgCU5xBY4g/JQ0AMIOZEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiiadhtz7T9mO2nbG+0fUO1/Fbbm22vrS5XdL5dAK0az/zs+yTdGBFP2j5B0hO2V1a1OyLibzrXHoB2Gc/87Fskbaluv2l7k6RTOt0YgPY6pM/stk+TdK6k1dWiRbbX2V5ie2qDdYZsD9se3qs99boF0LJxh9328ZLul/SFiNgp6W5JZ0iap5E9/1fHWi8iFkfEYEQMDmhS/Y4BtGRcYbc9oJGgfycividJEbEtIvZHxAFJX5c0v3NtAqhrPEfjLekeSZsi4vZRy2eMetinJG1of3sA2mU8R+PPl/RZSettr62WfUnSNbbnSQpJL0m6vgP9AWiT8RyN/6GkseZ7frj97QDoFL5BByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSMIR0b2N2f8j6eVRi06S9HrXGjg0/dpbv/Yl0Vur2tnbr0fE+8YqdDXs79q4PRwRgz1roKBfe+vXviR6a1W3euNtPJAEYQeS6HXYF/d4+yX92lu/9iXRW6u60ltPP7MD6J5e79kBdAlhB5LoSdhtX277GdvP276pFz00Yvsl2+uraaiHe9zLEtvbbW8YtWya7ZW2n6uux5xjr0e99cU03oVpxnv62vV6+vOuf2a3PVHSs5I+LulVSWskXRMRT3W1kQZsvyRpMCJ6/gUM2xdJ2iXp3oj4YLXsK5J2RMRt1R/KqRHx533S262SdvV6Gu9qtqIZo6cZl3SlpGvVw9eu0NdV6sLr1os9+3xJz0fECxHxtqTlkhb0oI++FxGPS9rxjsULJC2tbi/VyH+WrmvQW1+IiC0R8WR1+01JB6cZ7+lrV+irK3oR9lMkvTLq/qvqr/neQ9IPbD9he6jXzYxhekRsqW5vlTS9l82Moek03t30jmnG++a1a2X687o4QPduF0TEhyV9QtLnq7erfSlGPoP109jpuKbx7pYxphn/pV6+dq1Of15XL8K+WdLMUfdPrZb1hYjYXF1vl/SA+m8q6m0HZ9Ctrrf3uJ9f6qdpvMeaZlx98Nr1cvrzXoR9jaTZtmfZPlrS1ZJW9KCPd7F9XHXgRLaPk3SZ+m8q6hWSFla3F0p6sIe9/Ip+mca70TTj6vFr1/PpzyOi6xdJV2jkiPx/S7q5Fz006Ot0ST+tLht73ZukZRp5W7dXI8c2rpP0XkmrJD0n6VFJ0/qot29LWi9pnUaCNaNHvV2gkbfo6yStrS5X9Pq1K/TVldeNr8sCSXCADkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+H966EmhYle2EwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore data\n",
    "## YOUR CODE HERE ##\n",
    "show5(train_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "##Create the NN, the NN consists of 2 CNN layer n\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # First Convolutional Layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Second Convolutional Layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        # Flatten Layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(32 * 7 * 7, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions and pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##\n",
    "#Instantiate the model \n",
    "model = Model()\n",
    "\n",
    "#Specify the loss function \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#Specify the optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [250/7500], Loss: 0.03012233041226864\n",
      "Epoch [1/5], Step [500/7500], Loss: 0.17369571328163147\n",
      "Epoch [1/5], Step [750/7500], Loss: 0.005512060597538948\n",
      "Epoch [1/5], Step [1000/7500], Loss: 0.08840153366327286\n",
      "Epoch [1/5], Step [1250/7500], Loss: 0.004487529397010803\n",
      "Epoch [1/5], Step [1500/7500], Loss: 5.7924833527067676e-05\n",
      "Epoch [1/5], Step [1750/7500], Loss: 0.1803838163614273\n",
      "Epoch [1/5], Step [2000/7500], Loss: 0.10205134749412537\n",
      "Epoch [1/5], Step [2250/7500], Loss: 0.0828281044960022\n",
      "Epoch [1/5], Step [2500/7500], Loss: 0.056466277688741684\n",
      "Epoch [1/5], Step [2750/7500], Loss: 0.0005747312679886818\n",
      "Epoch [1/5], Step [3000/7500], Loss: 0.0024706916883587837\n",
      "Epoch [1/5], Step [3250/7500], Loss: 0.007965926080942154\n",
      "Epoch [1/5], Step [3500/7500], Loss: 0.002857196144759655\n",
      "Epoch [1/5], Step [3750/7500], Loss: 0.005220021586865187\n",
      "Epoch [1/5], Step [4000/7500], Loss: 0.03648676723241806\n",
      "Epoch [1/5], Step [4250/7500], Loss: 0.0005083727301098406\n",
      "Epoch [1/5], Step [4500/7500], Loss: 0.12988783419132233\n",
      "Epoch [1/5], Step [4750/7500], Loss: 0.0028537078760564327\n",
      "Epoch [1/5], Step [5000/7500], Loss: 0.0006490984233096242\n",
      "Epoch [1/5], Step [5250/7500], Loss: 0.0005840266239829361\n",
      "Epoch [1/5], Step [5500/7500], Loss: 0.007838497869670391\n",
      "Epoch [1/5], Step [5750/7500], Loss: 0.0006773230852559209\n",
      "Epoch [1/5], Step [6000/7500], Loss: 9.639484051149338e-05\n",
      "Epoch [1/5], Step [6250/7500], Loss: 0.0266127847135067\n",
      "Epoch [1/5], Step [6500/7500], Loss: 0.00025024876231327653\n",
      "Epoch [1/5], Step [6750/7500], Loss: 0.006251369137316942\n",
      "Epoch [1/5], Step [7000/7500], Loss: 0.0007285986212082207\n",
      "Epoch [1/5], Step [7250/7500], Loss: 0.0015979103045538068\n",
      "Epoch [1/5], Step [7500/7500], Loss: 0.009871792048215866\n",
      "Epoch [2/5], Step [250/7500], Loss: 0.00016102202062029392\n",
      "Epoch [2/5], Step [500/7500], Loss: 0.017011631280183792\n",
      "Epoch [2/5], Step [750/7500], Loss: 0.10500743985176086\n",
      "Epoch [2/5], Step [1000/7500], Loss: 0.00025517353788018227\n",
      "Epoch [2/5], Step [1250/7500], Loss: 0.001517881522886455\n",
      "Epoch [2/5], Step [1500/7500], Loss: 0.002110445871949196\n",
      "Epoch [2/5], Step [1750/7500], Loss: 0.0218488946557045\n",
      "Epoch [2/5], Step [2000/7500], Loss: 0.00046559455222450197\n",
      "Epoch [2/5], Step [2250/7500], Loss: 0.0007229630136862397\n",
      "Epoch [2/5], Step [2500/7500], Loss: 0.09800943732261658\n",
      "Epoch [2/5], Step [2750/7500], Loss: 0.00016607703582849354\n",
      "Epoch [2/5], Step [3000/7500], Loss: 0.04758647456765175\n",
      "Epoch [2/5], Step [3250/7500], Loss: 0.00148366903886199\n",
      "Epoch [2/5], Step [3500/7500], Loss: 0.0007267356850206852\n",
      "Epoch [2/5], Step [3750/7500], Loss: 0.0014015103224664927\n",
      "Epoch [2/5], Step [4000/7500], Loss: 0.0006666079279966652\n",
      "Epoch [2/5], Step [4250/7500], Loss: 0.118985615670681\n",
      "Epoch [2/5], Step [4500/7500], Loss: 0.00019308242190163583\n",
      "Epoch [2/5], Step [4750/7500], Loss: 0.004106355365365744\n",
      "Epoch [2/5], Step [5000/7500], Loss: 0.0004570794408209622\n",
      "Epoch [2/5], Step [5250/7500], Loss: 0.16252005100250244\n",
      "Epoch [2/5], Step [5500/7500], Loss: 0.0075130946934223175\n",
      "Epoch [2/5], Step [5750/7500], Loss: 0.14406128227710724\n",
      "Epoch [2/5], Step [6000/7500], Loss: 0.0035674928221851587\n",
      "Epoch [2/5], Step [6250/7500], Loss: 0.0002289645781274885\n",
      "Epoch [2/5], Step [6500/7500], Loss: 0.0002097076940117404\n",
      "Epoch [2/5], Step [6750/7500], Loss: 0.047953661531209946\n",
      "Epoch [2/5], Step [7000/7500], Loss: 0.004277775064110756\n",
      "Epoch [2/5], Step [7250/7500], Loss: 5.200477517064428e-06\n",
      "Epoch [2/5], Step [7500/7500], Loss: 0.001556595554575324\n",
      "Epoch [3/5], Step [250/7500], Loss: 0.0002760919160209596\n",
      "Epoch [3/5], Step [500/7500], Loss: 1.3560037359638955e-06\n",
      "Epoch [3/5], Step [750/7500], Loss: 0.0703495666384697\n",
      "Epoch [3/5], Step [1000/7500], Loss: 6.223347736522555e-05\n",
      "Epoch [3/5], Step [1250/7500], Loss: 1.5809282558620907e-05\n",
      "Epoch [3/5], Step [1500/7500], Loss: 0.0037829321809113026\n",
      "Epoch [3/5], Step [1750/7500], Loss: 0.00035744564956985414\n",
      "Epoch [3/5], Step [2000/7500], Loss: 0.031689535826444626\n",
      "Epoch [3/5], Step [2250/7500], Loss: 1.4960529370000586e-05\n",
      "Epoch [3/5], Step [2500/7500], Loss: 0.0022315173409879208\n",
      "Epoch [3/5], Step [2750/7500], Loss: 0.0024956262204796076\n",
      "Epoch [3/5], Step [3000/7500], Loss: 0.003008670173585415\n",
      "Epoch [3/5], Step [3250/7500], Loss: 0.00010234209185000509\n",
      "Epoch [3/5], Step [3500/7500], Loss: 0.0021688230335712433\n",
      "Epoch [3/5], Step [3750/7500], Loss: 2.3914206394692883e-05\n",
      "Epoch [3/5], Step [4000/7500], Loss: 0.02655499428510666\n",
      "Epoch [3/5], Step [4250/7500], Loss: 1.0162370017496869e-05\n",
      "Epoch [3/5], Step [4500/7500], Loss: 0.0018599549075588584\n",
      "Epoch [3/5], Step [4750/7500], Loss: 0.006214924156665802\n",
      "Epoch [3/5], Step [5000/7500], Loss: 0.00015091155364643782\n",
      "Epoch [3/5], Step [5250/7500], Loss: 0.0002796545159071684\n",
      "Epoch [3/5], Step [5500/7500], Loss: 0.08623301237821579\n",
      "Epoch [3/5], Step [5750/7500], Loss: 0.00020325154764577746\n",
      "Epoch [3/5], Step [6000/7500], Loss: 1.0862773706321605e-05\n",
      "Epoch [3/5], Step [6250/7500], Loss: 3.1441238661500392e-06\n",
      "Epoch [3/5], Step [6500/7500], Loss: 0.0012551499530673027\n",
      "Epoch [3/5], Step [6750/7500], Loss: 3.2870040740817785e-05\n",
      "Epoch [3/5], Step [7000/7500], Loss: 2.412378125882242e-05\n",
      "Epoch [3/5], Step [7250/7500], Loss: 0.04460250586271286\n",
      "Epoch [3/5], Step [7500/7500], Loss: 0.01053688582032919\n",
      "Epoch [4/5], Step [250/7500], Loss: 0.049835965037345886\n",
      "Epoch [4/5], Step [500/7500], Loss: 1.3112745364196599e-05\n",
      "Epoch [4/5], Step [750/7500], Loss: 0.02572186104953289\n",
      "Epoch [4/5], Step [1000/7500], Loss: 1.0117768397321925e-05\n",
      "Epoch [4/5], Step [1250/7500], Loss: 0.0011100656120106578\n",
      "Epoch [4/5], Step [1500/7500], Loss: 7.540597289334983e-05\n",
      "Epoch [4/5], Step [1750/7500], Loss: 8.888531738193706e-05\n",
      "Epoch [4/5], Step [2000/7500], Loss: 0.00010934700549114496\n",
      "Epoch [4/5], Step [2250/7500], Loss: 0.0020159033592790365\n",
      "Epoch [4/5], Step [2500/7500], Loss: 1.3202105947129894e-05\n",
      "Epoch [4/5], Step [2750/7500], Loss: 5.662434432451846e-07\n",
      "Epoch [4/5], Step [3000/7500], Loss: 0.10551438480615616\n",
      "Epoch [4/5], Step [3250/7500], Loss: 0.0003649016725830734\n",
      "Epoch [4/5], Step [3500/7500], Loss: 2.0205105101922527e-05\n",
      "Epoch [4/5], Step [3750/7500], Loss: 1.072880877472926e-06\n",
      "Epoch [4/5], Step [4000/7500], Loss: 0.06717328727245331\n",
      "Epoch [4/5], Step [4250/7500], Loss: 0.8879619836807251\n",
      "Epoch [4/5], Step [4500/7500], Loss: 0.000645651132799685\n",
      "Epoch [4/5], Step [4750/7500], Loss: 6.943750577192986e-06\n",
      "Epoch [4/5], Step [5000/7500], Loss: 0.00016400637105107307\n",
      "Epoch [4/5], Step [5250/7500], Loss: 0.0006391839124262333\n",
      "Epoch [4/5], Step [5500/7500], Loss: 0.00019671607878990471\n",
      "Epoch [4/5], Step [5750/7500], Loss: 0.006810544524341822\n",
      "Epoch [4/5], Step [6000/7500], Loss: 0.0016881561605259776\n",
      "Epoch [4/5], Step [6250/7500], Loss: 0.000427622435381636\n",
      "Epoch [4/5], Step [6500/7500], Loss: 0.029885457828640938\n",
      "Epoch [4/5], Step [6750/7500], Loss: 0.35350972414016724\n",
      "Epoch [4/5], Step [7000/7500], Loss: 0.0018812075722962618\n",
      "Epoch [4/5], Step [7250/7500], Loss: 0.0001458281622035429\n",
      "Epoch [4/5], Step [7500/7500], Loss: 0.0008838676149025559\n",
      "Epoch [5/5], Step [250/7500], Loss: 0.0002741117787081748\n",
      "Epoch [5/5], Step [500/7500], Loss: 0.00010529216524446383\n",
      "Epoch [5/5], Step [750/7500], Loss: 3.002230187121313e-05\n",
      "Epoch [5/5], Step [1000/7500], Loss: 1.7850736185209826e-05\n",
      "Epoch [5/5], Step [1250/7500], Loss: 0.0010469775879755616\n",
      "Epoch [5/5], Step [1500/7500], Loss: 0.00028842242318205535\n",
      "Epoch [5/5], Step [1750/7500], Loss: 5.200398391025374e-06\n",
      "Epoch [5/5], Step [2000/7500], Loss: 1.802978295017965e-05\n",
      "Epoch [5/5], Step [2250/7500], Loss: 0.0006274277111515403\n",
      "Epoch [5/5], Step [2500/7500], Loss: 0.0016687690513208508\n",
      "Epoch [5/5], Step [2750/7500], Loss: 2.667286025825888e-06\n",
      "Epoch [5/5], Step [3000/7500], Loss: 7.829740206943825e-05\n",
      "Epoch [5/5], Step [3250/7500], Loss: 0.0005646205390803516\n",
      "Epoch [5/5], Step [3500/7500], Loss: 3.832003130810335e-05\n",
      "Epoch [5/5], Step [3750/7500], Loss: 1.6838262126839254e-06\n",
      "Epoch [5/5], Step [4000/7500], Loss: 2.7715852866094792e-06\n",
      "Epoch [5/5], Step [4250/7500], Loss: 0.0692635253071785\n",
      "Epoch [5/5], Step [4500/7500], Loss: 2.6672919375414494e-06\n",
      "Epoch [5/5], Step [4750/7500], Loss: 0.04800388216972351\n",
      "Epoch [5/5], Step [5000/7500], Loss: 2.0861612881617475e-07\n",
      "Epoch [5/5], Step [5250/7500], Loss: 2.9802320611338473e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Step [5500/7500], Loss: 2.279867658216972e-06\n",
      "Epoch [5/5], Step [5750/7500], Loss: 0.0008191931410692632\n",
      "Epoch [5/5], Step [6000/7500], Loss: 1.3560008937929524e-06\n",
      "Epoch [5/5], Step [6250/7500], Loss: 2.3601334760314785e-05\n",
      "Epoch [5/5], Step [6500/7500], Loss: 2.2202630134415813e-06\n",
      "Epoch [5/5], Step [6750/7500], Loss: 0.0002479195536579937\n",
      "Epoch [5/5], Step [7000/7500], Loss: 0.0003261216334067285\n",
      "Epoch [5/5], Step [7250/7500], Loss: 1.5452244042535312e-05\n",
      "Epoch [5/5], Step [7500/7500], Loss: 0.011842424049973488\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "#Set up the GPU \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "#Specify the training hyperparameter \n",
    "num_epochs = 5 \n",
    "\n",
    "# Training loop\n",
    "total_steps = len(train_data_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        # Move images and labels to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training progress\n",
    "        if (i + 1) % 250 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_steps}], Loss: {loss.item()}\")\n",
    "\n",
    "# Training complete\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-28c8ea358805>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Plot and label the training and validation loss values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#plt.plot(num_epochs, val_values, label='Validation Loss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3019\u001b[0m     return gca().plot(\n\u001b[1;32m   3020\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \"\"\"\n\u001b[1;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_check_1d\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1337\u001b[0m     \u001b[0;34m\"\"\"Convert scalars to 1D arrays; pass-through arrays as is.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_1d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    730\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "#Plotting the training and validation loss if recorded\n",
    "train_values = loss\n",
    "#val_values = val_loss\n",
    "\n",
    "# Generate a sequence of integers to represent the epoch numbers\n",
    "num_epoch = range(1, num_epochs+1)\n",
    " \n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(num_epoch, train_values, label='Training Loss')\n",
    "#plt.plot(num_epochs, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(arange(0, epochs+1, 1))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.90%\n"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables for accuracy calculation\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Disable gradient calculation for evaluation\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_data_loader:\n",
    "        # Move images and labels to the device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Get predicted labels\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update total and correct counts\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: './trained_model/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-efce29b72dc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Save the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: './trained_model/'"
     ]
    }
   ],
   "source": [
    "## YOUR CODE HERE ##\n",
    "model_path = './trained_model/'\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
